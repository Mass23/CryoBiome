"""
Author: Susheel Bhanu BUSI
Affiliation: ESB group LCSB UniLU
Date: [2021-01-31]
Run: snakemake -s Snakefile --use-conda --cores 40 -rp
Latest modification:
"""

import glob

configfile:"config.yaml"
DATA_DIR=config['data_dir']
RESULTS_DIR=config['results_dir']
ENV_DIR=config['env_dir']
SRC_DIR=config['scripts_dir']
DB_DIR=config['database_dir']
SAMPLES=[line.strip() for line in open("modified_prokaryote_complete_accessions.txt", 'r')]    # if using a sample list instead of putting them in a config file
ASSEMBLY=[line.strip() for line in open("modified_assembly_list.txt", 'r')]
# SAMPLES=SAMPLES=[line.strip() for line in open("outgroups.txt", 'r')]	# used for TEST purposes
# ASSEMBLY=[line.strip() for line in open("ass_list", 'r')]		# used for TEST purposes

###########
rule all:
    input:
##        expand(os.path.join(DATA_DIR, "{sample}"), sample=SAMPLES),
##        os.path.join(RESULTS_DIR, "gRodon/gRodon.installed"),
##        expand(os.path.join(RESULTS_DIR, "prokka/{ass}.{type}"), ass=ASSEMBLY, type=["gff", "ffn"]),
##        expand(os.path.join(RESULTS_DIR, "prodigal/{ass}_CDS_names.txt"), ass=ASSEMBLY)
        expand(os.path.join(RESULTS_DIR, "prodigal/{ass}.{type}"), ass=ASSEMBLY, type=["gff", "faa", "ffn"]),
#        expand(os.path.join(RESULTS_DIR, "blast/{ass}.out"), ass=ASSEMBLY),
#        expand(os.path.join(RESULTS_DIR, "gRodon/{ass}_growth_prediction.txt"), ass=ASSEMBLY),
#        expand(os.path.join(RESULTS_DIR, "gRodon/merged_all_growth_prediction.txt")),
#        expand(os.path.join(RESULTS_DIR, "coRdon/{ass}_codon_counts.txt"), ass=ASSEMBLY),
#        expand(os.path.join(RESULTS_DIR, "coRdon/merged_all_codon_counts.txt")),
        expand(os.path.join(RESULTS_DIR, "hmmer_cag/{ass}.{type}"), ass=ASSEMBLY, type=["out", "out.dm"])

############################
# Download Genbank genomes #
############################
#rule genome_download:
#    output:
#        directory(os.path.join(DATA_DIR, "{sample}"))
#    log:
#        os.path.join("logs/download.{sample}.log")
#    conda:
#        os.path.join(ENV_DIR, "ncbi-genome-download.yaml")
#    message:
#        "Downloading FASTA, GFF and Protein-FASTA for {wildcards.sample}"
#    shell:
#        "(date && ncbi-genome-download -A {wildcards.sample} bacteria -s genbank --formats fasta,gff,protein-fasta --no-cache --verbose && date) &> {log}"

#################
# Initial Setup #
#################
rule install_gRodon:
    output:
        done=os.path.join(RESULTS_DIR, "gRodon/gRodon.installed")
    log:
        out=os.path.join("logs/setup.gRodon.log")
    conda:
        os.path.join(ENV_DIR, "gRodon.yaml")
    message:
        "Setup: install R-package gRodon"
    script:
        os.path.join(SRC_DIR, "install_gRodon.R")

##########
# Prokka #
##########
#rule prokka:
#    input:
#        os.path.join(DATA_DIR, "{ass}_genomic.fna.gz")
#    output:
#        FA=os.path.join(RESULTS_DIR, "data/{ass}.fna"),
#        GFF=os.path.join(RESULTS_DIR, "prokka/{ass}.gff"),
#        FFN=os.path.join(RESULTS_DIR, "prokka/{ass}.ffn")
#    log:
#        "logs/prokka.{ass}.log"
##    wildcard_constraints:
##        sample=SAMPLES,
##        ass=ASSEMBLY
#    threads:
#        config['prokka']['threads']
#    conda:
#        os.path.join(ENV_DIR, "prokka.yaml")
#    message:
#        "Running Prokka on {wildcards.ass}"
#    shell:
#        "(date && zcat {input} > {output.FA} && "
#        "export PATH={config[prokka][blast]}:$PATH && export PERL5LIB={config[prokka][path]} && "
#        "prokka {output.FA} --outdir $(dirname {output.GFF}) --prefix $(basename {wildcards.ass}) --cpus {threads} --force && date) &> {log}"

############
# Prodigal #
############
rule prodigal:
    input:
        os.path.join(DATA_DIR, "{ass}_genomic.fna.gz")
    output:
        FA=os.path.join(RESULTS_DIR, "data/{ass}.fna"),
        GFF=os.path.join(RESULTS_DIR, "prodigal/{ass}.gff"),
        FAA=os.path.join(RESULTS_DIR, "prodigal/{ass}.faa"),
        FFN=os.path.join(RESULTS_DIR, "prodigal/{ass}.ffn")
    log:
        "logs/annotation.prodigal.{ass}.log"
    threads: 
        config['prodigal']['threads']
    conda:
        os.path.join(ENV_DIR, "prodigal.yaml")
    message:
        "Annotation: Prodigal: {wildcards.ass}"
    shell:
        "(date && zcat {input} > {output.FA} && "
        "export PERL5LIB={config[prodigal][path]} && prodigal -i {output.FA} -a {output.FAA} -d {output.FFN} -o {output.GFF} -f gff && date) &> {log}"

#rule convert:
#    input:
#        FA=rules.prodigal.output.FA,
#        GFF=rules.prodigal.output.GFF
#    output:
#        BED=os.path.join(RESULTS_DIR, "prodigal/{ass}.bed"),
#        FFN=os.path.join(RESULTS_DIR, "prodigal/{ass}.ffn")
#    log:
#        "logs/convert.{ass}.log"
#    conda:
#        os.path.join(ENV_DIR, "bedtools.yaml")
#    message:
#        "Converting GFF to FFN for {wildcards.ass}"
#    shell:
#        """(date && awk '($3=="CDS" || $3=="gene" || $3=="tRNA" || $3=="tmRNA" || $3=="ncRNA" || $3=="rRNA") {{OFS="\t"; print $1,$4-1,$5}}' {input.GFF} > {output.BED} &&"""
#        """bedtools getfasta -fi {input.FA} -bed {output.BED} -fo {output.FFN} && date) &> {log}"""

#########
# BLAST #
#########
rule blast:
    input:
        rules.prodigal.output.FAA
    output:
        os.path.join(RESULTS_DIR, "blast/{ass}.out")
    params:
        db=config["blast"]["db"],
        max_hits=config["blast"]["max_hits"],
    threads:
        config["blast"]["threads"]
    log:
        "logs/blast.{ass}.log"
    conda:
        os.path.join(ENV_DIR, "blast.yaml")
    message:
        "Running BLAST against ribosomal protein DB for {wildcards.ass}"
    shell:
        """(date && blastp -query {input} -db {params.db} -evalue 1e-5 -outfmt "6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore" -out {output} -num_threads {threads} -max_target_seqs {params.max_hits} && date) &> {log}"""


################
# Preprocessing #
#################
rule preprocess:
    input:
        rules.prodigal.output.GFF
    output:
        os.path.join(RESULTS_DIR, "prodigal/{ass}_CDS_names.txt")
    log:
        "logs/preprocess.{ass}.log"
    message:
        "Preprocessing GFFs from {wildcards.ass}"
    shell:
        """(date && sed -n '/##FASTA/q;p' {input} | awk '$3=="CDS"' | awk '{{print $1,$9}}'| awk 'gsub(";.*","")' | awk 'gsub("ID=","")' | awk 'sub(/\.[^\.]+$/,".",$1)' | awk '{{print $1$NF}}' > {output} && date) &> {log}"""    

##################
# Running gRodon #
##################
rule gRodon:
    input:
        FFN=rules.prodigal.output.FFN,
        CDS=rules.preprocess.output,
        BLAST=rules.blast.output,
        installed=os.path.join(RESULTS_DIR, "gRodon/gRodon.installed")
    output:
        PRED=os.path.join(RESULTS_DIR, "gRodon/{ass}_growth_prediction.txt")
    log:
        "logs/gRodon.{ass}.log"
    conda:
        os.path.join(ENV_DIR, "gRodon.yaml")
    message:
        "Growth prediction using gRodon for {wildcards.ass}"
    script:
        os.path.join(SRC_DIR, "gRodon.R")

rule merge_gRodon:
    input:
        PRED=os.path.join(RESULTS_DIR, "gRodon/gRodon.installed")
    output:
        DF=os.path.join(RESULTS_DIR, "gRodon/merged_all_growth_prediction.txt")
    log:
        "logs/gRodon.merged.log"
    conda:
        os.path.join(ENV_DIR, "r-conda.yaml")
    message:
        "Merging gRodon output for all samples"
    script:
        os.path.join(SRC_DIR, "merge_gRodon.R") 

##################
# Running coRdon #
##################
rule coRdon:
    input:
        FNA=rules.prodigal.output.FA,
        installed=os.path.join(RESULTS_DIR, "gRodon/gRodon.installed")
    output:
        COUNT=os.path.join(RESULTS_DIR, "coRdon/{ass}_codon_counts.txt")
    log:
        "logs/coRdon.{ass}.log"
    conda:
        os.path.join(ENV_DIR, "gRodon.yaml")
    message:
        "Estimating Codon Usage Counts for {wildcards.ass}"
    script:
        os.path.join(SRC_DIR, "coRdon.R")

rule merge_coRdon:
    input:
        COUNT=os.path.join(RESULTS_DIR, "coRdon"),
        DUMMY=expand(os.path.join(RESULTS_DIR, "coRdon/{ass}_codon_counts.txt"), ass=ASSEMBLY)
    output:
        DF=os.path.join(RESULTS_DIR, "coRdon/merged_all_codon_counts.txt")
    log:
        "logs/coRdon.merged.log"
    conda:
        os.path.join(ENV_DIR, "r-conda.yaml")
    message:
        "Merging coRdon output for all samples"
    script:
        os.path.join(SRC_DIR, "merge_coRdon.R")

#########################
# Cold-adaptation genes #
#########################
rule hmmer_CAGs:
    input: 
        FAA=os.path.join(RESULTS_DIR, "prodigal/{ass}.faa")
    output:
        DM=os.path.join(RESULTS_DIR, "hmmer_cag/{ass}.out.dm"),
        OUT=os.path.join(RESULTS_DIR, "hmmer_cag/{ass}.out")
    log:
        "logs/hmmer_CAGs.{ass}.log"
    threads:
        config['hmmer']['threads']
    conda:
        os.path.join(ENV_DIR, "hmmer.yaml")
    params:
        hmm=config['hmmer']['CAGhmm']
    message:
        "Identifying Cold-adaptation genes (CAGs) for {wildcards.ass}"
    shell:
        "(date && (hmmsearch -E 0.01 --cpu {threads} --noali --notextw --tblout {output.OUT} --domtblout {output.DM} {params.hmm} {input.FAA}) > /dev/null && date) &> {log}"
